{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1: Easy Stright Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Important note:**\n",
    "\n",
    "The Minecraft world is generated using Microsoft Malmo's mission xml template, make sure to put the mission template in this directory (navigateDense.xml) in the MineRL python package location i.e. `~/anaconda3/envs/rltorch/lib/python3.7/site-packages/minerl/herobraine/env_specs/missions/`\n",
    "\n",
    "MineRL will use this mission file to create the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Agent Environment Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import minerl\n",
    "\n",
    "from logging import getLogger\n",
    "logger = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MineRL environment wrappers\n",
    "* The MineRL Gym Environment returns action and observation spaces as Dictionary spaces instead of Discrete spaces. We need a wrapper to map possible actions to discrete space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to sys path to acess env_wrappers.py\n",
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainerrl\n",
    "from chainerrl.wrappers import ContinuingTimeLimit\n",
    "from chainerrl.wrappers.atari_wrappers import FrameStack, ScaledFloatFrame\n",
    "\n",
    "# Environment wrapper borrowed from minerl sample code: \n",
    "# https://github.com/minerllabs/baselines/tree/master/general/chainerrl\n",
    "from env_wrappers import (\n",
    "    SerialDiscreteActionWrapper, CombineActionWrapper, SerialDiscreteCombineActionWrapper,\n",
    "    ContinuingTimeLimitMonitor,\n",
    "    MoveAxisWrapper, FrameSkip, ObtainPoVWrapper, PoVWithCompassAngleWrapper, GrayScaleWrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agruments for wrapper\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.frame_skip = None\n",
    "        self.gray_scale = False\n",
    "        self.env = 'MineRLNavigateDense'\n",
    "        self.frame_stack = None\n",
    "        self.disable_action_prior = False # False=Discrete of True=CombineDiscrete\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire function is borrowed from MineRL demo files:\n",
    "# https://github.com/minerllabs/baselines/blob/master/general/chainerrl/baselines/ppo.py#L124\n",
    "def wrap_env(env, test):\n",
    "\n",
    "        if isinstance(env, gym.wrappers.TimeLimit):\n",
    "            logger.info('Detected `gym.wrappers.TimeLimit`! Unwrap it and re-wrap our own time limit.')\n",
    "            env = env.env\n",
    "            max_episode_steps = env.spec.max_episode_steps\n",
    "            env = ContinuingTimeLimit(env, max_episode_steps=max_episode_steps)\n",
    "\n",
    "        # wrap env: observation...\n",
    "        # NOTE: wrapping order matters!\n",
    "\n",
    "        if test and args.monitor:\n",
    "            env = ContinuingTimeLimitMonitor(\n",
    "                env, os.path.join(args.outdir, 'monitor'),\n",
    "                mode='evaluation' if test else 'training', video_callable=lambda episode_id: True)\n",
    "        if args.frame_skip is not None:\n",
    "            env = FrameSkip(env, skip=args.frame_skip)\n",
    "        if args.gray_scale:\n",
    "            env = GrayScaleWrapper(env, dict_space_key='pov')\n",
    "        if args.env.startswith('MineRLNavigate'):\n",
    "            env = PoVWithCompassAngleWrapper(env)\n",
    "        else:\n",
    "            env = ObtainPoVWrapper(env)\n",
    "        env = MoveAxisWrapper(env, source=-1, destination=0)  # convert hwc -> chw as Chainer requires.\n",
    "        env = ScaledFloatFrame(env)\n",
    "        if args.frame_stack is not None and args.frame_stack > 0:\n",
    "            env = FrameStack(env, args.frame_stack, channel_order='chw')\n",
    "\n",
    "        # wrap env: action...\n",
    "        if not args.disable_action_prior:\n",
    "            env = SerialDiscreteActionWrapper(\n",
    "                env,\n",
    "                always_keys=[], reverse_keys=[], exclude_keys=['camera'], exclude_noop=False)\n",
    "        else:\n",
    "            env = CombineActionWrapper(env)\n",
    "            env = SerialDiscreteCombineActionWrapper(env)\n",
    "\n",
    "        return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_env = gym.make(\"MineRLNavigateDense-v0\") # A MineRLNavigate-v0 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = wrap_env(core_env, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize environment to check if mission XML working\n",
    "env.reset()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom policy network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of built in policies, we will use a custom policy because the default CNN Policy is not configured correctly to the current shape of the input observation pixels and rewards. The deafult MLP Policy works but doesn't perform very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from stable_baselines.a2c.utils import conv, linear, conv_to_fc\n",
    "from stable_baselines.common.policies import FeedForwardPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_cnn(scaled_images, **kwargs):\n",
    "    activ = tf.nn.relu\n",
    "    layer_1 = activ(conv(scaled_images, 'c1', n_filters=32, filter_size=2, stride=1, init_scale=np.sqrt(2), **kwargs))\n",
    "    layer_2 = activ(conv(layer_1, 'c2', n_filters=64, filter_size=2, stride=1, init_scale=np.sqrt(2), **kwargs))\n",
    "    layer_3 = activ(conv(layer_2, 'c3', n_filters=64, filter_size=2, stride=1, init_scale=np.sqrt(2), **kwargs))\n",
    "    layer_3 = conv_to_fc(layer_3)\n",
    "    return activ(linear(layer_3, 'fc1', n_hidden=512, init_scale=np.sqrt(2)))\n",
    "\n",
    "class CustomPolicy(FeedForwardPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomPolicy, self).__init__(*args, **kwargs, cnn_extractor=modified_cnn, feature_extraction=\"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO Model by OpenAI: https://openai.com/blog/openai-baselines-ppo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:136: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rewards are logged in tensorboard\n",
    "model = PPO2(policy = CustomPolicy,env=env, n_steps=64,\n",
    "            verbose=1, tensorboard_log=\"./test_tensorboard/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(4, 96, 128)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/rltorch/lib/python3.7/site-packages/stable_baselines/common/base_class.py:1143: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "-------------------------------------\n",
      "| approxkl           | 0.005878729  |\n",
      "| clipfrac           | 0.0859375    |\n",
      "| explained_variance | 0.00123      |\n",
      "| fps                | 13           |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 2.2969208    |\n",
      "| policy_loss        | -0.031599294 |\n",
      "| serial_timesteps   | 64           |\n",
      "| time_elapsed       | 4.43e-05     |\n",
      "| total_timesteps    | 64           |\n",
      "| value_loss         | 673.185      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.048252713 |\n",
      "| clipfrac           | 0.5078125   |\n",
      "| explained_variance | 0.898       |\n",
      "| fps                | 25          |\n",
      "| n_updates          | 100         |\n",
      "| policy_entropy     | 1.2821951   |\n",
      "| policy_loss        | 0.018677505 |\n",
      "| serial_timesteps   | 6400        |\n",
      "| time_elapsed       | 205         |\n",
      "| total_timesteps    | 6400        |\n",
      "| value_loss         | 51.58204    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0057589384 |\n",
      "| clipfrac           | 0.04296875   |\n",
      "| explained_variance | -0.837       |\n",
      "| fps                | 86           |\n",
      "| n_updates          | 200          |\n",
      "| policy_entropy     | 0.5075202    |\n",
      "| policy_loss        | 0.015058819  |\n",
      "| serial_timesteps   | 12800        |\n",
      "| time_elapsed       | 366          |\n",
      "| total_timesteps    | 12800        |\n",
      "| value_loss         | 4.002742     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009148234  |\n",
      "| clipfrac           | 0.15625      |\n",
      "| explained_variance | -1.47        |\n",
      "| fps                | 88           |\n",
      "| n_updates          | 300          |\n",
      "| policy_entropy     | 0.78835404   |\n",
      "| policy_loss        | -0.003630823 |\n",
      "| serial_timesteps   | 19200        |\n",
      "| time_elapsed       | 496          |\n",
      "| total_timesteps    | 19200        |\n",
      "| value_loss         | 2.6661503    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.021420624  |\n",
      "| clipfrac           | 0.28515625   |\n",
      "| explained_variance | -0.0618      |\n",
      "| fps                | 91           |\n",
      "| n_updates          | 400          |\n",
      "| policy_entropy     | 0.9543857    |\n",
      "| policy_loss        | -0.021080872 |\n",
      "| serial_timesteps   | 25600        |\n",
      "| time_elapsed       | 647          |\n",
      "| total_timesteps    | 25600        |\n",
      "| value_loss         | 6.696077     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.018159682  |\n",
      "| clipfrac           | 0.2578125    |\n",
      "| explained_variance | 0.542        |\n",
      "| fps                | 90           |\n",
      "| n_updates          | 500          |\n",
      "| policy_entropy     | 0.7180071    |\n",
      "| policy_loss        | -0.019143153 |\n",
      "| serial_timesteps   | 32000        |\n",
      "| time_elapsed       | 771          |\n",
      "| total_timesteps    | 32000        |\n",
      "| value_loss         | 1.7438935    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.007916898 |\n",
      "| clipfrac           | 0.09375     |\n",
      "| explained_variance | 0.936       |\n",
      "| fps                | 14          |\n",
      "| n_updates          | 600         |\n",
      "| policy_entropy     | 0.70072275  |\n",
      "| policy_loss        | -0.01924842 |\n",
      "| serial_timesteps   | 38400       |\n",
      "| time_elapsed       | 974         |\n",
      "| total_timesteps    | 38400       |\n",
      "| value_loss         | 17.899137   |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 9.279771e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.075         |\n",
      "| fps                | 87             |\n",
      "| n_updates          | 700            |\n",
      "| policy_entropy     | 0.12204138     |\n",
      "| policy_loss        | -1.8273946e-05 |\n",
      "| serial_timesteps   | 44800          |\n",
      "| time_elapsed       | 1.08e+03       |\n",
      "| total_timesteps    | 44800          |\n",
      "| value_loss         | 0.10060904     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.017115802  |\n",
      "| clipfrac           | 0.16015625   |\n",
      "| explained_variance | 0.955        |\n",
      "| fps                | 88           |\n",
      "| n_updates          | 800          |\n",
      "| policy_entropy     | 0.9952587    |\n",
      "| policy_loss        | -0.008957213 |\n",
      "| serial_timesteps   | 51200        |\n",
      "| time_elapsed       | 1.21e+03     |\n",
      "| total_timesteps    | 51200        |\n",
      "| value_loss         | 0.41378847   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009448508  |\n",
      "| clipfrac           | 0.05078125   |\n",
      "| explained_variance | -5.29        |\n",
      "| fps                | 90           |\n",
      "| n_updates          | 900          |\n",
      "| policy_entropy     | 0.8561654    |\n",
      "| policy_loss        | -0.010084156 |\n",
      "| serial_timesteps   | 57600        |\n",
      "| time_elapsed       | 1.32e+03     |\n",
      "| total_timesteps    | 57600        |\n",
      "| value_loss         | 2.5147808    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.01120595   |\n",
      "| clipfrac           | 0.21484375   |\n",
      "| explained_variance | -0.373       |\n",
      "| fps                | 91           |\n",
      "| n_updates          | 1000         |\n",
      "| policy_entropy     | 1.6231794    |\n",
      "| policy_loss        | -0.018128268 |\n",
      "| serial_timesteps   | 64000        |\n",
      "| time_elapsed       | 1.44e+03     |\n",
      "| total_timesteps    | 64000        |\n",
      "| value_loss         | 21.168724    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.035765715 |\n",
      "| clipfrac           | 0.37890625  |\n",
      "| explained_variance | 0.83        |\n",
      "| fps                | 90          |\n",
      "| n_updates          | 1100        |\n",
      "| policy_entropy     | 1.4127095   |\n",
      "| policy_loss        | -0.02402732 |\n",
      "| serial_timesteps   | 70400       |\n",
      "| time_elapsed       | 1.57e+03    |\n",
      "| total_timesteps    | 70400       |\n",
      "| value_loss         | 1.8864646   |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.039837938   |\n",
      "| clipfrac           | 0.421875      |\n",
      "| explained_variance | -0.154        |\n",
      "| fps                | 81            |\n",
      "| n_updates          | 1200          |\n",
      "| policy_entropy     | 0.8102983     |\n",
      "| policy_loss        | -0.0038755038 |\n",
      "| serial_timesteps   | 76800         |\n",
      "| time_elapsed       | 1.73e+03      |\n",
      "| total_timesteps    | 76800         |\n",
      "| value_loss         | 13.652698     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0052183596 |\n",
      "| clipfrac           | 0.0703125    |\n",
      "| explained_variance | 0.93         |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 1300         |\n",
      "| policy_entropy     | 0.209923     |\n",
      "| policy_loss        | 0.015339158  |\n",
      "| serial_timesteps   | 83200        |\n",
      "| time_elapsed       | 1.98e+03     |\n",
      "| total_timesteps    | 83200        |\n",
      "| value_loss         | 14.728639    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.09872188  |\n",
      "| clipfrac           | 0.1171875   |\n",
      "| explained_variance | 0.925       |\n",
      "| fps                | 25          |\n",
      "| n_updates          | 1400        |\n",
      "| policy_entropy     | 0.1908138   |\n",
      "| policy_loss        | 0.013533028 |\n",
      "| serial_timesteps   | 89600       |\n",
      "| time_elapsed       | 2.18e+03    |\n",
      "| total_timesteps    | 89600       |\n",
      "| value_loss         | 40.6991     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.081806235  |\n",
      "| clipfrac           | 0.453125     |\n",
      "| explained_variance | 0.994        |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 1500         |\n",
      "| policy_entropy     | 0.87506187   |\n",
      "| policy_loss        | -0.013167538 |\n",
      "| serial_timesteps   | 96000        |\n",
      "| time_elapsed       | 2.41e+03     |\n",
      "| total_timesteps    | 96000        |\n",
      "| value_loss         | 8.362006     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.026845757 |\n",
      "| clipfrac           | 0.29296875  |\n",
      "| explained_variance | -3.14       |\n",
      "| fps                | 88          |\n",
      "| n_updates          | 1600        |\n",
      "| policy_entropy     | 0.58109576  |\n",
      "| policy_loss        | 0.023905326 |\n",
      "| serial_timesteps   | 102400      |\n",
      "| time_elapsed       | 2.56e+03    |\n",
      "| total_timesteps    | 102400      |\n",
      "| value_loss         | 9.493836    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0061959377 |\n",
      "| clipfrac           | 0.078125     |\n",
      "| explained_variance | -1.48        |\n",
      "| fps                | 82           |\n",
      "| n_updates          | 1700         |\n",
      "| policy_entropy     | 0.56579965   |\n",
      "| policy_loss        | -0.004127279 |\n",
      "| serial_timesteps   | 108800       |\n",
      "| time_elapsed       | 2.68e+03     |\n",
      "| total_timesteps    | 108800       |\n",
      "| value_loss         | 0.28352848   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.009442705 |\n",
      "| clipfrac           | 0.140625    |\n",
      "| explained_variance | -1.44       |\n",
      "| fps                | 82          |\n",
      "| n_updates          | 1800        |\n",
      "| policy_entropy     | 1.4453727   |\n",
      "| policy_loss        | -0.01570386 |\n",
      "| serial_timesteps   | 115200      |\n",
      "| time_elapsed       | 2.8e+03     |\n",
      "| total_timesteps    | 115200      |\n",
      "| value_loss         | 1.1389368   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.014936781 |\n",
      "| clipfrac           | 0.16015625  |\n",
      "| explained_variance | 0.846       |\n",
      "| fps                | 25          |\n",
      "| n_updates          | 1900        |\n",
      "| policy_entropy     | 0.5169791   |\n",
      "| policy_loss        | 0.005258754 |\n",
      "| serial_timesteps   | 121600      |\n",
      "| time_elapsed       | 2.96e+03    |\n",
      "| total_timesteps    | 121600      |\n",
      "| value_loss         | 359.77353   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.013545932  |\n",
      "| clipfrac           | 0.0703125    |\n",
      "| explained_variance | 0.857        |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 2000         |\n",
      "| policy_entropy     | 0.16144092   |\n",
      "| policy_loss        | -0.008737316 |\n",
      "| serial_timesteps   | 128000       |\n",
      "| time_elapsed       | 3.19e+03     |\n",
      "| total_timesteps    | 128000       |\n",
      "| value_loss         | 705.3187     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.058852084 |\n",
      "| clipfrac           | 0.3984375   |\n",
      "| explained_variance | -0.498      |\n",
      "| fps                | 86          |\n",
      "| n_updates          | 2100        |\n",
      "| policy_entropy     | 1.660319    |\n",
      "| policy_loss        | -0.0345593  |\n",
      "| serial_timesteps   | 134400      |\n",
      "| time_elapsed       | 3.28e+03    |\n",
      "| total_timesteps    | 134400      |\n",
      "| value_loss         | 19.75422    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.053540308   |\n",
      "| clipfrac           | 0.265625      |\n",
      "| explained_variance | -0.116        |\n",
      "| fps                | 90            |\n",
      "| n_updates          | 2200          |\n",
      "| policy_entropy     | 0.35280794    |\n",
      "| policy_loss        | -0.0004283858 |\n",
      "| serial_timesteps   | 140800        |\n",
      "| time_elapsed       | 3.45e+03      |\n",
      "| total_timesteps    | 140800        |\n",
      "| value_loss         | 13.811572     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.008803897 |\n",
      "| clipfrac           | 0.0859375   |\n",
      "| explained_variance | -0.0991     |\n",
      "| fps                | 14          |\n",
      "| n_updates          | 2300        |\n",
      "| policy_entropy     | 0.16820298  |\n",
      "| policy_loss        | 0.009273609 |\n",
      "| serial_timesteps   | 147200      |\n",
      "| time_elapsed       | 3.69e+03    |\n",
      "| total_timesteps    | 147200      |\n",
      "| value_loss         | 61.887077   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.022775486  |\n",
      "| clipfrac           | 0.11328125   |\n",
      "| explained_variance | 0.911        |\n",
      "| fps                | 26           |\n",
      "| n_updates          | 2400         |\n",
      "| policy_entropy     | 0.21662815   |\n",
      "| policy_loss        | 0.0075961165 |\n",
      "| serial_timesteps   | 153600       |\n",
      "| time_elapsed       | 3.97e+03     |\n",
      "| total_timesteps    | 153600       |\n",
      "| value_loss         | 5.4356413    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.03130269  |\n",
      "| clipfrac           | 0.0703125   |\n",
      "| explained_variance | 0.992       |\n",
      "| fps                | 26          |\n",
      "| n_updates          | 2500        |\n",
      "| policy_entropy     | 0.06796829  |\n",
      "| policy_loss        | 0.006640394 |\n",
      "| serial_timesteps   | 160000      |\n",
      "| time_elapsed       | 4.23e+03    |\n",
      "| total_timesteps    | 160000      |\n",
      "| value_loss         | 0.7445292   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0071529965 |\n",
      "| clipfrac           | 0.03515625   |\n",
      "| explained_variance | 0.0124       |\n",
      "| fps                | 26           |\n",
      "| n_updates          | 2600         |\n",
      "| policy_entropy     | 0.10460399   |\n",
      "| policy_loss        | -0.01130389  |\n",
      "| serial_timesteps   | 166400       |\n",
      "| time_elapsed       | 4.49e+03     |\n",
      "| total_timesteps    | 166400       |\n",
      "| value_loss         | 42.508507    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.011587343   |\n",
      "| clipfrac           | 0.04296875    |\n",
      "| explained_variance | 0.988         |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 2700          |\n",
      "| policy_entropy     | 0.12186618    |\n",
      "| policy_loss        | -0.0043572425 |\n",
      "| serial_timesteps   | 172800        |\n",
      "| time_elapsed       | 4.76e+03      |\n",
      "| total_timesteps    | 172800        |\n",
      "| value_loss         | 1.1453185     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.25140026  |\n",
      "| clipfrac           | 0.2734375   |\n",
      "| explained_variance | 0.971       |\n",
      "| fps                | 26          |\n",
      "| n_updates          | 2800        |\n",
      "| policy_entropy     | 0.27561527  |\n",
      "| policy_loss        | 0.027502067 |\n",
      "| serial_timesteps   | 179200      |\n",
      "| time_elapsed       | 5.03e+03    |\n",
      "| total_timesteps    | 179200      |\n",
      "| value_loss         | 4.2972903   |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.03775765    |\n",
      "| clipfrac           | 0.046875      |\n",
      "| explained_variance | 0.996         |\n",
      "| fps                | 26            |\n",
      "| n_updates          | 2900          |\n",
      "| policy_entropy     | 0.057703305   |\n",
      "| policy_loss        | -0.0019512363 |\n",
      "| serial_timesteps   | 185600        |\n",
      "| time_elapsed       | 5.3e+03       |\n",
      "| total_timesteps    | 185600        |\n",
      "| value_loss         | 0.3883719     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.07827899    |\n",
      "| clipfrac           | 0.09765625    |\n",
      "| explained_variance | 0.991         |\n",
      "| fps                | 14            |\n",
      "| n_updates          | 3000          |\n",
      "| policy_entropy     | 0.1052634     |\n",
      "| policy_loss        | -0.0024002455 |\n",
      "| serial_timesteps   | 192000        |\n",
      "| time_elapsed       | 5.58e+03      |\n",
      "| total_timesteps    | 192000        |\n",
      "| value_loss         | 3.9303458     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.245785e-14   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.175         |\n",
      "| fps                | 90             |\n",
      "| n_updates          | 3100           |\n",
      "| policy_entropy     | 2.2228372e-05  |\n",
      "| policy_loss        | -2.2584572e-08 |\n",
      "| serial_timesteps   | 198400         |\n",
      "| time_elapsed       | 5.7e+03        |\n",
      "| total_timesteps    | 198400         |\n",
      "| value_loss         | 0.5621662      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.07503039  |\n",
      "| clipfrac           | 0.3046875   |\n",
      "| explained_variance | 0.635       |\n",
      "| fps                | 82          |\n",
      "| n_updates          | 3200        |\n",
      "| policy_entropy     | 0.4855294   |\n",
      "| policy_loss        | -0.03874159 |\n",
      "| serial_timesteps   | 204800      |\n",
      "| time_elapsed       | 5.78e+03    |\n",
      "| total_timesteps    | 204800      |\n",
      "| value_loss         | 1.9912359   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.03221457   |\n",
      "| clipfrac           | 0.07421875   |\n",
      "| explained_variance | 0.969        |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 3300         |\n",
      "| policy_entropy     | 0.115014195  |\n",
      "| policy_loss        | 0.0013422999 |\n",
      "| serial_timesteps   | 211200       |\n",
      "| time_elapsed       | 6e+03        |\n",
      "| total_timesteps    | 211200       |\n",
      "| value_loss         | 2.7217994    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.6012235e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.991         |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 3400          |\n",
      "| policy_entropy     | 0.027371414   |\n",
      "| policy_loss        | -0.0006908955 |\n",
      "| serial_timesteps   | 217600        |\n",
      "| time_elapsed       | 6.26e+03      |\n",
      "| total_timesteps    | 217600        |\n",
      "| value_loss         | 1.5248605     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.034208648  |\n",
      "| clipfrac           | 0.21484375   |\n",
      "| explained_variance | -2.27        |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 3500         |\n",
      "| policy_entropy     | 0.6208205    |\n",
      "| policy_loss        | -0.010158138 |\n",
      "| serial_timesteps   | 224000       |\n",
      "| time_elapsed       | 6.36e+03     |\n",
      "| total_timesteps    | 224000       |\n",
      "| value_loss         | 458.35565    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.0305301e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0722       |\n",
      "| fps                | 90            |\n",
      "| n_updates          | 3600          |\n",
      "| policy_entropy     | 0.00067377544 |\n",
      "| policy_loss        | 1.2223609e-07 |\n",
      "| serial_timesteps   | 230400        |\n",
      "| time_elapsed       | 6.52e+03      |\n",
      "| total_timesteps    | 230400        |\n",
      "| value_loss         | 67.83718      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.012038676   |\n",
      "| clipfrac           | 0.01953125    |\n",
      "| explained_variance | 0.994         |\n",
      "| fps                | 25            |\n",
      "| n_updates          | 3700          |\n",
      "| policy_entropy     | 0.0748672     |\n",
      "| policy_loss        | -0.0040425695 |\n",
      "| serial_timesteps   | 236800        |\n",
      "| time_elapsed       | 6.71e+03      |\n",
      "| total_timesteps    | 236800        |\n",
      "| value_loss         | 0.83494616    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.013440935  |\n",
      "| clipfrac           | 0.02734375   |\n",
      "| explained_variance | 0.996        |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 3800         |\n",
      "| policy_entropy     | 0.05701595   |\n",
      "| policy_loss        | 0.0024910895 |\n",
      "| serial_timesteps   | 243200       |\n",
      "| time_elapsed       | 6.98e+03     |\n",
      "| total_timesteps    | 243200       |\n",
      "| value_loss         | 0.35251573   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.025011273 |\n",
      "| clipfrac           | 0.1171875   |\n",
      "| explained_variance | 0.936       |\n",
      "| fps                | 24          |\n",
      "| n_updates          | 3900        |\n",
      "| policy_entropy     | 0.13918938  |\n",
      "| policy_loss        | 0.019496504 |\n",
      "| serial_timesteps   | 249600      |\n",
      "| time_elapsed       | 7.25e+03    |\n",
      "| total_timesteps    | 249600      |\n",
      "| value_loss         | 8.637121    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017233682 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.966         |\n",
      "| fps                | 24            |\n",
      "| n_updates          | 4000          |\n",
      "| policy_entropy     | 0.047648966   |\n",
      "| policy_loss        | -0.0008466126 |\n",
      "| serial_timesteps   | 256000        |\n",
      "| time_elapsed       | 7.53e+03      |\n",
      "| total_timesteps    | 256000        |\n",
      "| value_loss         | 3.7106009     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.009843556    |\n",
      "| clipfrac           | 0.12890625     |\n",
      "| explained_variance | 0.379          |\n",
      "| fps                | 74             |\n",
      "| n_updates          | 4100           |\n",
      "| policy_entropy     | 1.5168588      |\n",
      "| policy_loss        | -0.00097552966 |\n",
      "| serial_timesteps   | 262400         |\n",
      "| time_elapsed       | 7.74e+03       |\n",
      "| total_timesteps    | 262400         |\n",
      "| value_loss         | 2.451985       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.0342686e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0583         |\n",
      "| fps                | 87             |\n",
      "| n_updates          | 4200           |\n",
      "| policy_entropy     | 0.009807409    |\n",
      "| policy_loss        | -5.8477744e-06 |\n",
      "| serial_timesteps   | 268800         |\n",
      "| time_elapsed       | 7.93e+03       |\n",
      "| total_timesteps    | 268800         |\n",
      "| value_loss         | 75.1689        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007835877  |\n",
      "| clipfrac           | 0.01171875    |\n",
      "| explained_variance | 0.983         |\n",
      "| fps                | 26            |\n",
      "| n_updates          | 4300          |\n",
      "| policy_entropy     | 0.060465388   |\n",
      "| policy_loss        | -0.0007446788 |\n",
      "| serial_timesteps   | 275200        |\n",
      "| time_elapsed       | 8.14e+03      |\n",
      "| total_timesteps    | 275200        |\n",
      "| value_loss         | 1.7099805     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.4876361    |\n",
      "| clipfrac           | 0.2421875    |\n",
      "| explained_variance | 0.997        |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 4400         |\n",
      "| policy_entropy     | 0.14288273   |\n",
      "| policy_loss        | -0.010899781 |\n",
      "| serial_timesteps   | 281600       |\n",
      "| time_elapsed       | 8.41e+03     |\n",
      "| total_timesteps    | 281600       |\n",
      "| value_loss         | 0.51354194   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.015605275 |\n",
      "| clipfrac           | 0.0703125   |\n",
      "| explained_variance | 0.997       |\n",
      "| fps                | 24          |\n",
      "| n_updates          | 4500        |\n",
      "| policy_entropy     | 0.08954553  |\n",
      "| policy_loss        | 0.006760876 |\n",
      "| serial_timesteps   | 288000      |\n",
      "| time_elapsed       | 8.69e+03    |\n",
      "| total_timesteps    | 288000      |\n",
      "| value_loss         | 0.28235045  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.055015087  |\n",
      "| clipfrac           | 0.0625       |\n",
      "| explained_variance | 0.996        |\n",
      "| fps                | 24           |\n",
      "| n_updates          | 4600         |\n",
      "| policy_entropy     | 0.03587174   |\n",
      "| policy_loss        | -0.014921079 |\n",
      "| serial_timesteps   | 294400       |\n",
      "| time_elapsed       | 8.96e+03     |\n",
      "| total_timesteps    | 294400       |\n",
      "| value_loss         | 0.3339465    |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 300k steps ~ 1hr 30min\n",
    "\n",
    "model.learn(total_timesteps=300000,log_interval=100)\n",
    "model.save(\"level1.5_ppo2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
